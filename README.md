# 🤖 Ollama Chatbot using LangChain
# Project Recording:
https://drive.google.com/file/d/1_fECrLBuO-Idled79VmUqDxoaOXSYYAE/view?usp=drive_link

This project demonstrates how to build a local AI chatbot using Ollama for running Large Language Models (LLMs) and LangChain for managing the conversation flow, memory, and chaining logic.

It’s a minimal, modular chatbot application that runs entirely on your local machine without requiring any external APIs or cloud services.

# 📌 Features
🧠 Local LLM Inference with Ollama (LLaMA3, Mistral)

🔗 LangChain Integration for prompt templates, conversation memory, and chains

💬 Chat Interface via CLI or Streamlit (optional)

⚙️ Easily extendable to support tools, agents, or RAG pipelines

# 🛠️ Tech Stack
LangChain – Chain, memory, and prompt templating

Ollama – Local inference with open LLMs

Python – Scripting and orchestration

Streamlit / CLI – Interface options

# 🔮 Future Enhancements
Add Retrieval-Augmented Generation (RAG) with local documents

Support for tools and LangChain Agents

Enable voice input/output using Whisper and TTS

Chat history and logging

# 🙏 Acknowledgements
LangChain

Ollama

Open-source LLM community
